# GPT-4o チャットアプリ設計・構築ガイド（Terraform対応）

## 🎯 プロジェクト概要

友人がGPT-4oと継続的に会話できるチャットアプリの設計・構築ガイドです。ローカル開発から本番環境まで対応し、Terraformでインフラを管理します。

### 主要機能
- ChatGPTライクなUI/UX
- OpenAI API経由でGPT-4o利用
- 会話履歴の永続化と記憶機能
- 定期的な会話要約とシステムプロンプト更新
- 友人の情報・好み・特徴を記憶する仕組み
- 会話のエクスポート機能

## 🏗️ システム設計思想

### アプリケーション構成
**フロントエンド**: シンプルなSPA（Single Page Application）として設計し、ChatGPTと同じようなユーザー体験を提供します。リアルタイムでメッセージが表示され、タイピングインジケーターも実装して自然な会話感を演出します。

**バックエンド**: サーバーレス構成を採用し、必要な時だけリソースを使用することでコストを最小化します。APIゲートウェイ経由でLambda関数を呼び出し、各機能を独立した関数として分離します。

**データ管理**: 会話履歴は構造化データとしてDynamoDBに保存し、長期記憶用の要約データはMarkdownファイルとしてS3に保存します。この2層構造により、短期的な会話フローと長期的な記憶を効率的に管理します。

### 記憶システムの設計
**短期記憶**: 直近の会話（10-20件程度）をリアルタイムで参照し、文脈を維持します。

**中期記憶**: 過去1週間程度の会話を要約し、重要な話題や感情の変化を抽出します。

**長期記憶**: 月単位で会話を総括し、友人の性格、興味、人間関係、価値観などを体系的に整理します。これらの情報をMarkdownファイルとして構造化し、システムプロンプトに動的に組み込みます。

## 🏠 ローカル開発環境の設計

### 開発用データストレージ
ローカル開発では軽量なSQLiteデータベースを使用し、本番環境のDynamoDBと同じデータ構造を模倣します。ファイルストレージはローカルディスクを使用し、S3の代替として機能させます。

### 開発フロー
Docker Composeを使用して、フロントエンド開発サーバー、バックエンドAPI、ローカルデータベースを一括で起動できる環境を構築します。これにより、本番環境に近い状態でローカル開発が可能になります。

### 環境の切り替え
環境変数とコンフィグファイルを使い分けることで、ローカル開発、ステージング、本番環境を簡単に切り替えられるようにします。API エンドポイント、データベース接続先、ストレージパスなどを環境ごとに適切に設定します。

## ☁️ 本番環境のインフラ設計（AWS + Terraform）

### 基本構成
**超低コスト構成**: AWS Lambda + DynamoDB + S3 + CloudFront + API Gateway
**代替構成**: Vercel（フロントエンド） + AWS Lambda（バックエンド） + Supabase（データベース）

### Terraformによるインフラ管理
すべてのAWSリソースをTerraformで定義し、Infrastructure as Codeとして管理します。開発、ステージング、本番環境を同一の設定ファイルから環境変数で切り替えて構築できるようにします。

### セキュリティとアクセス管理
IAMロールとポリシーを最小権限の原則で設計し、各Lambdaが必要最小限のリソースにのみアクセスできるように制限します。OpenAI APIキーなどの機密情報はAWS Secrets Managerで管理し、環境変数として安全に注入します。

### モニタリングとログ管理
CloudWatchを使用してアプリケーションのメトリクスとログを一元管理し、異常な使用量やエラーを早期に検知できるアラートシステムを構築します。

## 💾 データ設計

### DynamoDB テーブル設計
**会話履歴テーブル**: パーティションキーに日付ベースのconversationId、ソートキーにタイムスタンプを使用し、効率的なクエリと適切なデータ分散を実現します。

**ユーザー情報テーブル**: 友人の基本情報、好み、会話スタイルの好み、重要な個人情報を構造化して保存します。

**要約データテーブル**: 週次・月次の会話要約、抽出されたキーワード、感情分析結果を保存し、長期記憶の構築に活用します。

### S3 ストレージ設計
**Markdownファイル**: 人間が読みやすい形式で会話要約を保存し、必要に応じて手動での編集も可能にします。

**バックアップ**: 重要な会話データの定期バックアップを自動化し、データ損失のリスクを最小化します。

## 🔄 データフローの設計

### 会話の処理フロー
1. ユーザーがメッセージを送信
2. API Gatewayが受信し、Lambda関数を起動
3. Lambda関数が過去の会話履歴とユーザー情報を取得
4. 会話要約ファイルから長期記憶を読み込み
5. 動的にシステムプロンプトを構築
6. OpenAI APIにリクエストを送信
7. 応答を受け取り、DynamoDBに保存
8. フロントエンドに応答を返送

### 記憶の更新フロー
週に1回程度の頻度で、過去の会話を自動的に要約し、重要な情報を抽出してMarkdownファイルを更新します。この処理は別のLambda関数として実装し、CloudWatch Eventsでスケジュール実行します。

## 🎨 フロントエンド設計

### UI/UX設計
ChatGPTと同じレイアウトとインタラクションパターンを採用し、友人が違和感なく使用できるようにします。メッセージの送受信、タイピングインジケーター、メッセージの時系列表示、スクロール制御などを自然に実装します。

### レスポンシブ対応
デスクトップ、タブレット、スマートフォンすべてで快適に使用できるレスポンシブデザインを採用します。特にスマートフォンでの使いやすさを重視し、タッチ操作に最適化します。

### オフライン対応
ネットワーク接続が不安定な環境でも基本的な閲覧ができるよう、Service Workerを使用したキャッシュ機能を実装します。

## 🔧 バックエンド設計

### マイクロサービス設計
各機能を独立したLambda関数として実装し、単一責任の原則に従って設計します：

**チャット機能**: メッセージの送受信とOpenAI API連携
**履歴管理**: 会話履歴の保存・取得
**要約生成**: 定期的な会話要約の生成
**ユーザー管理**: 友人の情報管理

### エラーハンドリング
OpenAI APIの制限やネットワークエラーに対する適切なエラーハンドリングを実装し、ユーザーにわかりやすいエラーメッセージを表示します。また、一時的な障害時の自動リトライ機能も組み込みます。

### パフォーマンス最適化
Lambdaのコールドスタート時間を最小化するため、必要な依存関係を最小限に抑え、コードサイズを最適化します。また、DynamoDBとS3へのアクセスパターンを最適化し、レスポンス時間を向上させます。

## 💰 コスト最適化戦略

### AWS無料枠の活用
DynamoDB、Lambda、S3の無料枠を最大限活用し、小規模な使用量であれば月額数ドル程度で運用できるように設計します。

### 使用量監視
CloudWatchを使用してコストと使用量を継続的に監視し、予想以上の費用が発生する前にアラートが通知されるシステムを構築します。

### 段階的スケーリング
初期は最小構成で開始し、使用量の増加に応じて段階的にリソースを追加できる柔軟な設計にします。

## 🛡️ セキュリティ設計

### データプライバシー
友人の会話データは暗号化して保存し、適切なアクセス制御を実装します。また、データの保持期間を設定し、古いデータは自動的に削除される仕組みを構築します。

### APIセキュリティ
API Gatewayでレート制限を設定し、異常なアクセスから保護します。また、CORS設定を適切に行い、許可されたドメインからのみアクセスできるようにします。

### 機密情報管理
OpenAI APIキーなどの機密情報はAWS Secrets Managerで管理し、アプリケーションコードには直接記述しません。

## 📁 プロジェクト構造

```
gpt4o-chat-app/
├── frontend/                 # React フロントエンド
├── backend/                  # Lambda 関数群
├── infrastructure/           # Terraform設定
│   ├── environments/         # 環境別設定
│   ├── modules/             # 再利用可能なモジュール
│   └── shared/              # 共通リソース
├── docs/                    # ドキュメント
├── scripts/                 # デプロイ・運用スクリプト
└── docker/                  # ローカル開発用
```

## 🚀 デプロイ戦略

### 段階的デプロイ
開発環境、ステージング環境、本番環境の3段階でデプロイを行い、各段階でテストとレビューを実施します。

### 自動化
GitHub ActionsまたはAWS CodePipelineを使用してCI/CDパイプラインを構築し、コードのプッシュからデプロイまでを自動化します。

### ロールバック戦略
問題が発生した場合に素早く前のバージョンに戻せるよう、Terraformの状態管理と合わせてロールバック手順を確立します。

## 📈 運用・監視

### ログ管理
すべてのLambda関数とAPIの実行ログをCloudWatchで一元管理し、問題の早期発見と対処を可能にします。

### メトリクス監視
応答時間、エラー率、使用量などの重要なメトリクスを継続的に監視し、パフォーマンスの劣化を早期に検知します。

### アラート設定
異常な活動やエラーの急増を検知した際に、メールやSlackで即座に通知されるアラートシステムを構築します。

この設計により、友人が安心してGPT-4oと長期的な関係を築ける、温かみのあるチャットアプリケーションを構築できます。